{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1c43d985ae7492",
   "metadata": {},
   "source": [
    "## Vision Transformer (ViT) Fine-Tuning on Modified Mini-GCD Dataset for Cloud Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd570d31afab2125",
   "metadata": {},
   "source": [
    "### 0. Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ee77875996e54",
   "metadata": {},
   "source": [
    "#### 0.1 Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf371239420015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T11:55:08.448342Z",
     "start_time": "2025-02-22T11:54:56.401243Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim import AdamW\n",
    "from transformers import ViTModel, ViTForImageClassification, ViTFeatureExtractor\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd6126f66646696",
   "metadata": {},
   "source": [
    "#### 0.2 Checking GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515010810120fe34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:39:29.088288Z",
     "start_time": "2025-02-21T14:39:28.876013Z"
    }
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17877a613653e7d",
   "metadata": {},
   "source": [
    "#### 0.3 Setting hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c461129d75506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:47:39.967064Z",
     "start_time": "2025-02-21T14:47:39.962333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset directories\n",
    "selected_data_dir_idx = 1 # Index of the selected dataset directory\n",
    "root_data_dir = \"datasets\"\n",
    "data_dir = [ \"mini-GCD-modified\", \"GCD-modified\"] # Dataset directories\n",
    "\n",
    "# Model directory and filename\n",
    "model_folder = \"models\" # Model folder\n",
    "model_filename = os.path.join(model_folder, \"vit_model.pth\") # Model filename\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 30 # Number of epochs to train\n",
    "batch_size = 8 # Batch size\n",
    "learning_rate = 3e-5 # Learning rate\n",
    "patience = 10 # Number of epochs with no improvement before early stopping\n",
    "\n",
    "# Results directory\n",
    "scenario = \"v0\" # Scenario name\n",
    "results_dir = \"results/vit/\" + data_dir[selected_data_dir_idx] + \"/\" + scenario + \"/\" # Results directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b0ecd9d61cf38",
   "metadata": {},
   "source": [
    "#### 0.4 Create Directories and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba23db8a1062cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:47:41.467873Z",
     "start_time": "2025-02-21T14:47:41.463148Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create directories\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Create results directory\n",
    "def try_create_results_dir(results_dir):\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    print(f\"Results Directory: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbd973",
   "metadata": {},
   "source": [
    "#### 0.5 Set up logging configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(log_dir=\"logs\"):\n",
    "    # Properly join paths using Path objects\n",
    "    base_path = Path(results_dir).resolve()\n",
    "    log_path = base_path / log_dir\n",
    "    \n",
    "    # Create logs directory inside results directory if it doesn't exist\n",
    "    log_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create timestamp for unique log file\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    log_filename = Path(log_path) / f'training_log_{timestamp}.txt'\n",
    "    \n",
    "    # Create formatters\n",
    "    file_formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s',\n",
    "                                     datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    console_formatter = logging.Formatter('%(asctime)s | %(message)s',\n",
    "                                        datefmt='%H:%M:%S')\n",
    "    \n",
    "    # Create and configure file handler\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "    \n",
    "    # Create and configure console handler\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "    \n",
    "    # Get logger and add handlers\n",
    "    logger = logging.getLogger('training')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "# Initialize logger\n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b16ae208a5c83c3",
   "metadata": {},
   "source": [
    "#### 1. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c773ae43af27d07a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:47:48.119941Z",
     "start_time": "2025-02-21T14:47:43.214346Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "\n",
    "# Define train dataloader with online data augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# Define validation and test dataloaders\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# Specify the dataset directories\n",
    "train_dir = os.path.join(root_data_dir, data_dir[selected_data_dir_idx], \"train\")\n",
    "val_dir = os.path.join(root_data_dir, data_dir[selected_data_dir_idx], \"val\")\n",
    "test_dir = os.path.join(root_data_dir, data_dir[selected_data_dir_idx], \"test\")\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform_train)\n",
    "val_dataset = ImageFolder(root=val_dir, transform=transform_val)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform_test)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Class Names\n",
    "class_names = train_dataset.classes\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Show number of training samples per class\n",
    "train_class_counts = {class_names[i]: 0 for i in range(len(class_names))}\n",
    "for _, label in train_dataset:\n",
    "    train_class_counts[class_names[label]] += 1\n",
    "print(\"Train Class Counts:\", train_class_counts)\n",
    "\n",
    "# Display the number of training samples\n",
    "print(f\"Total number of training samples: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2eafa6c6e92ff2",
   "metadata": {},
   "source": [
    "#### 1.3. Display Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56d78cf4cabf58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:47:55.611200Z",
     "start_time": "2025-02-21T14:47:55.327299Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display Sample Images\n",
    "def show_images(dataloader, class_names):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "    for idx, ax in enumerate(axes):\n",
    "        img = images[idx].permute(1, 2, 0).numpy()\n",
    "        img = (img * 0.5 + 0.5)  # Unnormalize\n",
    "        img = np.clip(img, 0, 1)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(class_names[labels[idx]])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(train_loader, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e83c5577d52587",
   "metadata": {},
   "source": [
    "### 2. Load ViT and Feature Extractor (Pre-trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b885c35c6ebd899f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:48:04.904378Z",
     "start_time": "2025-02-21T14:48:03.955624Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate ViT feature extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ecd908564e15",
   "metadata": {},
   "source": [
    "#### 2.1. Setup ViT-based Image Classifier with ViT Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a8347d258e9e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:48:07.803030Z",
     "start_time": "2025-02-21T14:48:07.496530Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the ViTClassifier with ViT feature extractor\n",
    "class ViTClassifier(nn.Module):\n",
    "    def __init__(self, vit_model, num_classes):\n",
    "        super(ViTClassifier, self).__init__()\n",
    "        self.vit_model = vit_model\n",
    "        self.norm = nn.LayerNorm(vit_model.config.hidden_size)  # Layer normalization\n",
    "        self.dropout = nn.Dropout(0.3)  # Lower dropout rate\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(vit_model.config.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use CLS token for feature representation\n",
    "        cls_token = self.vit_model(x).last_hidden_state[:, 0, :]\n",
    "        features = self.norm(cls_token)\n",
    "        features = self.dropout(features)\n",
    "        out = self.mlp(features)\n",
    "        return out\n",
    "\n",
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Instantiate classifier\n",
    "num_classes = len(class_names)\n",
    "classifier = ViTClassifier(vit_model, num_classes).to(device)\n",
    "print(f\"Trainable Parameters: {count_trainable_params(classifier):,}\")\n",
    "\n",
    "# Define Optimizer\n",
    "# optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "optimizer = AdamW(classifier.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "\n",
    "# Define Learning rate scheduler\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# Define Loss function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab26ba85aa3e70df",
   "metadata": {},
   "source": [
    "### 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401939542b560ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T15:09:34.651798Z",
     "start_time": "2025-02-21T14:48:08.640281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train_model(\n",
    "        classifier: nn.Module, \n",
    "        train_loader: DataLoader, \n",
    "        val_loader: DataLoader,\n",
    "        epochs: int = 30\n",
    "        ) -> tuple[list, list, int]:\n",
    "    \"\"\"\n",
    "    Train the model and return the training and validation losses\n",
    "    \"\"\"\n",
    "    \n",
    "    # Log training configuration\n",
    "    logger.info(\"=== Training Configuration ===\")\n",
    "    logger.info(f\"Learning Rate: {learning_rate}\")\n",
    "    logger.info(f\"Batch Size: {batch_size}\")\n",
    "    logger.info(f\"Number of Epochs: {num_epochs}\")\n",
    "    logger.info(\"============================\\n\")\n",
    "\n",
    "    # Initialize variables\n",
    "    train_losses: list = []\n",
    "    val_losses: list = []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    current_epochs: int = 0\n",
    "\n",
    "    # Training and validation loop\n",
    "    for epoch in range(epochs):\n",
    "        current_epochs = epoch + 1\n",
    "\n",
    "        classifier.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = classifier(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation loop\n",
    "        classifier.eval()\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = classifier(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Save the best model\n",
    "            torch.save(classifier.state_dict(), model_filename)\n",
    "            saved = True\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            saved = False\n",
    "            if patience_counter >= patience:\n",
    "                logger.info(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f} -> Early Stopping\")\n",
    "                break\n",
    "\n",
    "        # Log the losses\n",
    "        logger.info(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\" + (\" [*]\" if saved else \"\"))\n",
    "        \n",
    "    return train_losses, val_losses, current_epochs\n",
    "\n",
    "def plot_losses(train_losses, val_losses, num_epochs=num_epochs):\n",
    "    # Plot training and validation losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs+1), val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Save the plot first\n",
    "    plot_filename = os.path.join(results_dir, \"loss_plot.png\")\n",
    "    plt.savefig(plot_filename)\n",
    "    logger.info(f\"Loss plot saved to {plot_filename}\")\n",
    "    \n",
    "    # Then show it\n",
    "    plt.show()\n",
    "\n",
    "# Train the model and plot losses\n",
    "train_losses, val_losses, current_epochs = train_model(classifier, train_loader, val_loader, epochs=num_epochs)\n",
    "plot_losses(train_losses, val_losses, num_epochs=current_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e04e802a3396cf",
   "metadata": {},
   "source": [
    "#### 3.1. (Re)load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91149fed1b7c6b56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T15:31:36.304770Z",
     "start_time": "2025-02-21T15:31:35.854328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving is currently handled in the training loop\n",
    "# torch.save(classifier.state_dict(), model_filename)\n",
    "\n",
    "# Load the model\n",
    "classifier.load_state_dict(torch.load(model_filename))\n",
    "\n",
    "# Evaluate the model\n",
    "# classifier.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46700e3145875e4",
   "metadata": {},
   "source": [
    "### 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d20b2fdeb6353",
   "metadata": {},
   "source": [
    "#### 4.1. Utility Functions for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4271125b8a61ed4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T15:31:40.957175Z",
     "start_time": "2025-02-21T15:31:40.947418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "def predict_model(classifier, dataloader: DataLoader, class_names):\n",
    "    \"\"\"\n",
    "    Utility function to predict model on a dataset\n",
    "    :param classifier:\n",
    "    :param dataloader:\n",
    "    :param class_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    classifier.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = classifier(inputs)\n",
    "\n",
    "            # Get probabilities and predictions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "def generate_confusion_matrix(labels, preds, class_names, save_results=False):\n",
    "    \"\"\"\n",
    "    Utility function to generate confusion matrix\n",
    "    :param labels:\n",
    "    :param preds:\n",
    "    :param class_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Create Confusion Matrix\n",
    "    cm = confusion_matrix(labels, preds, labels=range(len(class_names)))\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if save_results:\n",
    "        try_create_results_dir(results_dir)\n",
    "        plt.savefig(results_dir + \"confusion_matrix.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def generate_classification_report(labels, preds, class_names, save_results=False):\n",
    "    \"\"\"\n",
    "    Utility function to generate classification report\n",
    "    :param labels:\n",
    "    :param preds:\n",
    "    :param class_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Generate Classification Report\n",
    "    report = classification_report(labels, preds, target_names=class_names)\n",
    "    print(report)\n",
    "\n",
    "    if save_results:\n",
    "        try_create_results_dir(results_dir)\n",
    "        with open(results_dir + \"classification_report.txt\", \"w\") as f:\n",
    "            f.write(report)\n",
    "\n",
    "def evaluate_model(classifier, dataloader, class_names, save_results=False):\n",
    "    \"\"\"\n",
    "    Utility wrapper function to evaluate model on a dataset\n",
    "    :param classifier:\n",
    "    :param dataloader:\n",
    "    :param class_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    preds, labels, probs = predict_model(classifier, dataloader, class_names)\n",
    "    generate_confusion_matrix(labels, preds, class_names, save_results)\n",
    "    generate_classification_report(labels, preds, class_names, save_results)\n",
    "    return preds, labels, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1758e0927a95d3e1",
   "metadata": {},
   "source": [
    "#### 4.2. Utility Function for Plotting Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe35fc8461afb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T15:31:42.550277Z",
     "start_time": "2025-02-21T15:31:42.543898Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot Random Samples\n",
    "def plot_random_samples(dataset, preds, labels, probs, class_names, num_cols=4, num_samples=5, save_results=False):\n",
    "    num_samples = min(num_samples, len(dataset))\n",
    "\n",
    "    # Randomly select indices\n",
    "    random_indices = random.sample(range(len(dataset)), num_samples)\n",
    "\n",
    "    # Calculate number of rows needed\n",
    "    num_rows = (num_samples + num_cols - 1) // num_cols\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 3 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        image, true_label = dataset[idx]\n",
    "        image = (image * 0.5 + 0.5)  # Unnormalize\n",
    "        image = np.clip(image, 0, 1)\n",
    "        pred_label = preds[idx]\n",
    "        prob = probs[idx, pred_label]  # Probability of predicted class\n",
    "\n",
    "        axes[i].imshow(image.permute(1, 2, 0))  # Convert CHW to HWC for plotting\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].set_title(\n",
    "            f\"True: {class_names[true_label]}\\n\"\n",
    "            f\"Pred: {class_names[pred_label]} ({prob:.2f})\"\n",
    "        )\n",
    "\n",
    "    # Hide any remaining empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_results:\n",
    "        try_create_results_dir(results_dir)\n",
    "        plt.savefig(results_dir + \"random_samples.png\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bab6331e4349b0",
   "metadata": {},
   "source": [
    "#### 4.3. Evaluate Model on train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccaab8bbfd85692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T15:32:15.477674Z",
     "start_time": "2025-02-21T15:31:44.620956Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate Model on train dataset\n",
    "print(\"Evaluating model on train dataset:\")\n",
    "evaluate_model(classifier, train_loader, class_names)\n",
    "\n",
    "# Evaluate Model on test dataset\n",
    "print(\"Evaluating model on test dataset:\")\n",
    "preds, labels, probs = evaluate_model(classifier, test_loader, class_names, save_results=True)\n",
    "\n",
    "# Plot random samples\n",
    "plot_random_samples(test_dataset, preds, labels, probs, class_names, num_cols=4, num_samples=16, save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc33c8082fcf114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
