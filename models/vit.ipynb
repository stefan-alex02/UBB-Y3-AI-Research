{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Vision Transformer (ViT) Fine-Tuning on Modified Mini-GCD Dataset for Cloud Image Classification",
   "id": "ee1c43d985ae7492"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 0. Setup Environment",
   "id": "cd570d31afab2125"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 0.1 Imports",
   "id": "445ee77875996e54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim import AdamW\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n"
   ],
   "id": "e5bf371239420015",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 0.2 Checking for GPU availability",
   "id": "6fd6126f66646696"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "id": "515010810120fe34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 0.3 Setting hyperparams",
   "id": "d17877a613653e7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dataset directories\n",
    "data_dirs = [ \"mini-GCD-modified\", \"GCD-modified\"] # Dataset directories\n",
    "selected_data_dir = data_dirs[1] # Selected dataset directory\n",
    "\n",
    "# Model directory and filename\n",
    "model_folder = \"models\" # Model folder\n",
    "model_filename = os.path.join(model_folder, \"vit_model.pth\") # Model filename\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 30 # Number of epochs to train\n",
    "patience = 10 # Number of epochs with no improvement before early stopping\n",
    "\n",
    "# Results directory\n",
    "scenario = \"v1\" # Scenario name\n",
    "results_dir = \"results/vit/\" + selected_data_dir + \"/\" + scenario + \"/\" # Results directory"
   ],
   "id": "5c1c461129d75506",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 0.4 Create Directories and Utility Functions",
   "id": "9f1b0ecd9d61cf38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create directories\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Create results directory\n",
    "def try_create_results_dir(results_dir):\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    print(f\"Results Directory: {results_dir}\")"
   ],
   "id": "8eba23db8a1062cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Loading the Dataset",
   "id": "5b16ae208a5c83c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define train dataloader with online data augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# Define validation and test dataloaders\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# Specify the dataset directories\n",
    "train_dir = os.path.join(selected_data_dir, \"train\")\n",
    "val_dir = os.path.join(selected_data_dir, \"val\")\n",
    "test_dir = os.path.join(selected_data_dir, \"test\")\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform_train)\n",
    "val_dataset = ImageFolder(root=val_dir, transform=transform_val)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform_val)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Class Names\n",
    "class_names = train_dataset.classes\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Show number of training samples per class\n",
    "train_class_counts = {class_names[i]: 0 for i in range(len(class_names))}\n",
    "for _, label in train_dataset:\n",
    "    train_class_counts[class_names[label]] += 1\n",
    "print(\"Train Class Counts:\", train_class_counts)\n",
    "\n",
    "# Display the number of training samples\n",
    "print(f\"Total number of training samples: {len(train_dataset)}\")"
   ],
   "id": "c773ae43af27d07a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.3. Display Sample Images",
   "id": "7d2eafa6c6e92ff2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display Sample Images\n",
    "def show_images(dataloader, class_names):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "    for idx, ax in enumerate(axes):\n",
    "        img = images[idx].permute(1, 2, 0).numpy()\n",
    "        img = (img * 0.5 + 0.5)  # Unnormalize\n",
    "        img = np.clip(img, 0, 1)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(class_names[labels[idx]])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(train_loader, class_names)"
   ],
   "id": "cd56d78cf4cabf58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Load ViT Feature Extractor (Pretrained)",
   "id": "93e83c5577d52587"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load ViT Feature Extractor (Pretrained)\n",
    "from transformers import ViTModel, ViTForImageClassification, ViTFeatureExtractor\n",
    "\n",
    "# Instantiate ViT feature extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ],
   "id": "b885c35c6ebd899f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1. Setup Diffusion-based Image Classifier with ViT Feature Extractor",
   "id": "8b4ecd908564e15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the ViTClassifier with ViT feature extractor\n",
    "class ViTClassifier(nn.Module):\n",
    "    def __init__(self, vit_model, num_classes):\n",
    "        super(ViTClassifier, self).__init__()\n",
    "        self.vit_model = vit_model\n",
    "        self.norm = nn.LayerNorm(vit_model.config.hidden_size)  # Layer normalization\n",
    "        self.dropout = nn.Dropout(0.3)  # Lower dropout rate\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(vit_model.config.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use CLS token for feature representation\n",
    "        cls_token = self.vit_model(x).last_hidden_state[:, 0, :]\n",
    "        features = self.norm(cls_token)\n",
    "        features = self.dropout(features)\n",
    "        out = self.mlp(features)\n",
    "        return out\n",
    "\n",
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Instantiate classifier with ViT feature extractor\n",
    "num_classes = len(class_names)\n",
    "classifier = ViTClassifier(vit_model, num_classes).to(device)\n",
    "print(f\"Trainable Parameters: {count_trainable_params(classifier):,}\")\n",
    "\n",
    "# Define Optimizer\n",
    "# optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "optimizer = AdamW(classifier.parameters(), lr=3e-5, weight_decay=0.01)\n",
    "\n",
    "# Define Learning rate scheduler\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# Define Loss function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)"
   ],
   "id": "cf5a8347d258e9e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Train the model",
   "id": "ab26ba85aa3e70df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "def train_model(classifier, train_loader, val_loader, epochs=30):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    current_epochs = 0\n",
    "\n",
    "    # Training and validation loop\n",
    "    for epoch in range(epochs):\n",
    "        current_epochs = epoch + 1\n",
    "\n",
    "        classifier.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = classifier(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation loop\n",
    "        classifier.eval()\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = classifier(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Save the best model\n",
    "            torch.save(classifier.state_dict(), model_filename)\n",
    "            saved = True\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            saved = False\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f} -> Early Stopping\")\n",
    "                break\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\" + (\" [*]\" if saved else \"\"))\n",
    "\n",
    "    return train_losses, val_losses, current_epochs\n",
    "\n",
    "def plot_losses(train_losses, val_losses, num_epochs=num_epochs):\n",
    "    # Plot training and validation losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs+1), val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Train the model and plot losses\n",
    "train_losses, val_losses, current_epochs = train_model(classifier, train_loader, val_loader, epochs=num_epochs)\n",
    "plot_losses(train_losses, val_losses, num_epochs=current_epochs)"
   ],
   "id": "6401939542b560ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.1. (Re)load the Model",
   "id": "55e04e802a3396cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Saving is currently handled in the training loop\n",
    "# torch.save(classifier.state_dict(), model_filename)\n",
    "\n",
    "# Load the model\n",
    "classifier.load_state_dict(torch.load(model_filename))\n",
    "\n",
    "# Evaluate the model\n",
    "# classifier.eval()"
   ],
   "id": "91149fed1b7c6b56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Evaluation",
   "id": "f46700e3145875e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.1. Utility Functions for Evaluation",
   "id": "404d20b2fdeb6353"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate Model\n",
    "def predict_model(classifier, dataloader: DataLoader, class_names):\n",
    "    \"\"\"\n",
    "    Utility function to predict model on a dataset\n",
    "    :param classifier:\n",
    "    :param dataloader:\n",
    "    :param class_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    classifier.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = classifier(inputs)\n",
    "\n",
    "            # Get probabilities and predictions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "def generate_confusion_matrix(labels, preds, class_names, save_results=False):\n",
    "    \"\"\"\n",
    "    Utility function to generate confusion matrix\n",
    "    :param labels:\n",
    "    :param preds:\n",
    "    :param class_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Create Confusion Matrix\n",
    "    cm = confusion_matrix(labels, preds, labels=range(len(class_names)))\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if save_results:\n",
    "        try_create_results_dir(results_dir)\n",
    "        plt.savefig(results_dir + \"confusion_matrix.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def generate_classification_report(labels, preds, class_names, save_results=False):\n",
    "    \"\"\"\n",
    "    Utility function to generate classification report\n",
    "    :param labels:\n",
    "    :param preds:\n",
    "    :param class_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Generate Classification Report\n",
    "    report = classification_report(labels, preds, target_names=class_names)\n",
    "    print(report)\n",
    "\n",
    "    if save_results:\n",
    "        try_create_results_dir(results_dir)\n",
    "        with open(results_dir + \"classification_report.txt\", \"w\") as f:\n",
    "            f.write(report)\n",
    "\n",
    "def evaluate_model(classifier, dataloader, class_names, save_results=False):\n",
    "    \"\"\"\n",
    "    Utility wrapper function to evaluate model on a dataset\n",
    "    :param classifier:\n",
    "    :param dataloader:\n",
    "    :param class_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    preds, labels, probs = predict_model(classifier, dataloader, class_names)\n",
    "    generate_confusion_matrix(labels, preds, class_names, save_results)\n",
    "    generate_classification_report(labels, preds, class_names, save_results)\n",
    "    return preds, labels, probs"
   ],
   "id": "4271125b8a61ed4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.2. Utility Function for Plotting Random Samples",
   "id": "1758e0927a95d3e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot Random Samples\n",
    "def plot_random_samples(dataset, preds, labels, probs, class_names, num_cols=4, num_samples=5, save_results=False):\n",
    "    num_samples = min(num_samples, len(dataset))\n",
    "\n",
    "    # Randomly select indices\n",
    "    random_indices = random.sample(range(len(dataset)), num_samples)\n",
    "\n",
    "    # Calculate number of rows needed\n",
    "    num_rows = (num_samples + num_cols - 1) // num_cols\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 3 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        image, true_label = dataset[idx]\n",
    "        image = (image * 0.5 + 0.5)  # Unnormalize\n",
    "        image = np.clip(image, 0, 1)\n",
    "        pred_label = preds[idx]\n",
    "        prob = probs[idx, pred_label]  # Probability of predicted class\n",
    "\n",
    "        axes[i].imshow(image.permute(1, 2, 0))  # Convert CHW to HWC for plotting\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].set_title(\n",
    "            f\"True: {class_names[true_label]}\\n\"\n",
    "            f\"Pred: {class_names[pred_label]} ({prob:.2f})\"\n",
    "        )\n",
    "\n",
    "    # Hide any remaining empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_results:\n",
    "        try_create_results_dir(results_dir)\n",
    "        plt.savefig(results_dir + \"random_samples.png\")\n",
    "\n",
    "    plt.show()"
   ],
   "id": "6abe35fc8461afb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.3. Evaluate Model on train and test datasets",
   "id": "55bab6331e4349b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate Model on train dataset\n",
    "evaluate_model(classifier, train_loader, class_names)\n",
    "\n",
    "# Evaluate Model on test dataset\n",
    "preds, labels, probs = evaluate_model(classifier, test_loader, class_names, save_results=True)\n",
    "\n",
    "# Plot random samples\n",
    "plot_random_samples(test_dataset, preds, labels, probs, class_names, num_cols=4, num_samples=8, save_results=True)"
   ],
   "id": "3ccaab8bbfd85692",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
