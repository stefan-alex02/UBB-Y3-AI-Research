2025-04-26 17:09:22 - âœ¨ INFO - [pipeline.py:69] - ğŸš€ Initializing Classification Pipeline...
2025-04-26 17:09:22 - âœ¨ INFO - [pipeline.py:70] - Dataset: mini-GCD
2025-04-26 17:09:22 - âœ¨ INFO - [pipeline.py:71] - Model: dummycnn
2025-04-26 17:09:22 - âœ¨ INFO - [pipeline.py:72] - Output Dir: results_pipeline
2025-04-26 17:09:22 - âœ¨ INFO - [pipeline.py:73] - Seed: 42
2025-04-26 17:09:22 - âœ¨ INFO - [datasets.py:137] - FIXED: Loaded 75 train images and 75 test images.
2025-04-26 17:09:22 - âœ¨ INFO - [datasets.py:83] - ğŸ“ Dataset 'mini-GCD' loaded. Structure: FIXED. Classes: 3
2025-04-26 17:09:22 - âœ¨ INFO - [pipeline.py:86] - ğŸ’» Device: CUDA
2025-04-26 17:09:22 - âœ¨ INFO - [pipeline.py:154] - âœ¨ Initializing NEW model: dummycnn...
2025-04-26 17:09:22 - âœ¨ INFO - [adapters.py:120] - ğŸ¤– Initializing SkorchImageClassifier with device: {device}
2025-04-26 17:09:22 - âœ¨ INFO - [adapters.py:121] - Callbacks: [] (DEBUG: Forced empty)
2025-04-26 17:09:22 - âœ¨ INFO - [pipeline.py:160] - âœ… New model adapter created.
2025-04-26 17:09:22 - âœ¨ INFO - [pipeline.py:185] - â• Added method to pipeline: single_train with config: {'val_size': 0.25, 'save_results': True, 'name': 'single_train', 'dataset_name': 'mini-GCD', 'model_name': 'dummycnn'}
2025-04-26 17:09:22 - âœ¨ INFO - [pipeline.py:185] - â• Added method to pipeline: single_eval with config: {'save_results': True, 'name': 'single_eval', 'dataset_name': 'mini-GCD', 'model_name': 'dummycnn'}
2025-04-26 17:09:22 - âœ¨ INFO - [pipeline.py:189] - ğŸ Starting pipeline execution with 2 steps...
2025-04-26 17:09:22 - âœ¨ INFO - [pipeline.py:199] - 
--- Running Step 1/2: single_train ---
2025-04-26 17:09:22 - âœ¨ INFO - [methods.py:448] - ğŸš€ Starting Single Train process...
2025-04-26 17:09:22 - âœ¨ INFO - [datasets.py:218] - Split data: 56 train, 19 validation samples.
2025-04-26 17:09:22 - âœ¨ INFO - [methods.py:473] - ğŸ’ª Starting training on 56 samples, validating on 19 samples...
2025-04-26 17:09:22 - âœ¨ INFO - [adapters.py:222] - Passing validation data (paths and labels) directly to super().fit.
2025-04-26 17:09:23 - âœ¨ INFO - [methods.py:487] - âœ… Single Train completed.
2025-04-26 17:09:23 - âŒ ERROR - [methods.py:514] - âŒ Single Train failed: "Key 'valid_loss' was not found in history."
Traceback (most recent call last):
  File "C:\Users\Stefan\Documents\Github\UBB-Y3-AI-Research\model_src\pipeline\methods.py", line 491, in run_single_train
    best_epoch = np.argmin(history[:, 'valid_loss']) # Assuming EarlyStopping loads best
                           ~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Stefan\.venv\Lib\site-packages\skorch\history.py", line 291, in __getitem__
    raise KeyError(keyerror_msg.format(key))
KeyError: "Key 'valid_loss' was not found in history."
2025-04-26 17:09:23 - âœ¨ INFO - [pipeline.py:199] - 
--- Running Step 2/2: single_eval ---
2025-04-26 17:09:23 - âœ¨ INFO - [methods.py:542] - ğŸš€ Starting Single Evaluation on Test Set...
2025-04-26 17:09:23 - âœ¨ INFO - [methods.py:565] - ğŸ§ª Evaluating model on 75 test samples...
2025-04-26 17:09:23 - âŒ ERROR - [methods.py:607] - âŒ Single Evaluation failed: Dataset does not have consistent lengths.
Traceback (most recent call last):
  File "C:\Users\Stefan\Documents\Github\UBB-Y3-AI-Research\model_src\pipeline\methods.py", line 569, in run_single_eval
    y_pred = model_adapter.predict(X_test.tolist()) # Pass list of paths
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Stefan\.venv\Lib\site-packages\skorch\classifier.py", line 232, in predict
    return self.predict_proba(X).argmax(axis=1)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Stefan\.venv\Lib\site-packages\skorch\classifier.py", line 200, in predict_proba
    return super().predict_proba(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Stefan\.venv\Lib\site-packages\skorch\net.py", line 1625, in predict_proba
    for yp in self.forward_iter(X, training=False):
  File "C:\Users\Stefan\.venv\Lib\site-packages\skorch\net.py", line 1468, in forward_iter
    dataset = self.get_dataset(X)
              ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Stefan\.venv\Lib\site-packages\skorch\net.py", line 1746, in get_dataset
    return dataset(X, y, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Stefan\.venv\Lib\site-packages\skorch\dataset.py", line 159, in __init__
    len_X = get_len(X)
            ^^^^^^^^^^
  File "C:\Users\Stefan\.venv\Lib\site-packages\skorch\dataset.py", line 82, in get_len
    raise ValueError("Dataset does not have consistent lengths.")
ValueError: Dataset does not have consistent lengths.
2025-04-26 17:09:23 - âœ¨ INFO - [pipeline.py:284] - 
ğŸ Pipeline execution finished in 0.89 seconds.
2025-04-26 17:09:23 - âœ¨ INFO - [pipeline.py:288] - ğŸ’¾ Saving final model state to: results_pipeline\mini-GCD\dummycnn\final_pipeline_model.pt
2025-04-26 17:09:23 - âœ¨ INFO - [pipeline.py:294] - âœ… Final model saved successfully.
2025-04-26 17:09:23 - âœ¨ INFO - [main.py:148] - 
--- Pipeline Completed ---
