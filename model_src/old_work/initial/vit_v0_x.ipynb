{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Vision Transformer on Modified Mini-GCD Dataset",
   "id": "43a89628678b6b1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 0. Setup Environment",
   "id": "449b41ceed4e3a17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from sympy.strategies.core import switch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "# Get the number of GPUs\n",
    "print(torch.cuda.device_count())\n",
    "# Get the current GPU device\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name())"
   ],
   "id": "73a50d9054a3df12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Load Simplified and Modified Mini-GCD Dataset",
   "id": "a2a1824b831fa881"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import transformers\n",
    "import accelerate\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\n",
    "])\n",
    "\n",
    "# Load Dataset\n",
    "data_dir = \"../modified-mini-GCD\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Class Names\n",
    "class_names = train_dataset.classes  # ['1_clearsky', '2_cloudy', '3_overcast']\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Show number of training samples per class\n",
    "train_class_counts = {class_names[i]: 0 for i in range(len(class_names))}\n",
    "for i, (image, label) in enumerate(train_dataset):\n",
    "    print(i, image.shape, label)\n",
    "    train_class_counts[class_names[label]] += 1\n",
    "print(\"Train Class Counts:\", train_class_counts)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "\n",
    "# Calculate sampling weights for each sample\n",
    "class_sample_count = [train_class_counts[name] for name in class_names]  # Class counts\n",
    "class_weights = [1.0 / count for count in class_sample_count]  # Inverse of class frequency\n",
    "sample_weights = [class_weights[label] for _, label in train_dataset]  # Assign weight to each sample\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "for i, (image, label) in enumerate(train_loader):\n",
    "    print(i, image.shape, label)"
   ],
   "id": "f0a2ca4e1a802d0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.1. Display Sample Images",
   "id": "833c9e78e26685bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Display Sample Images\n",
    "def show_images(dataloader, class_names, num_samples=5):\n",
    "    images, labels = [], []\n",
    "    for batch_images, batch_labels in dataloader:\n",
    "        images.append(batch_images)\n",
    "        labels.append(batch_labels)\n",
    "        if len(images) * batch_images.size(0) >= num_samples:\n",
    "            break\n",
    "\n",
    "    images = torch.cat(images)[:num_samples]\n",
    "    labels = torch.cat(labels)[:num_samples]\n",
    "\n",
    "    num_cols = 5\n",
    "    num_rows = (num_samples + num_cols - 1) // num_cols\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 3 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, ax in enumerate(axes):\n",
    "        if idx < num_samples:\n",
    "            img = images[idx].permute(1, 2, 0).numpy()  # Convert to HWC format\n",
    "            # Unnormalize according to ImageNet normalization\n",
    "            img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "            img = np.clip(img, 0, 1)\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(class_names[labels[idx]])\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show images before training\n",
    "show_images(train_loader, class_names, num_samples=50)"
   ],
   "id": "5d5e3e34ae44ae1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Load Pretrained Stable Diffusion Model",
   "id": "e8d3b04663f8921a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load Pretrained Stable Diffusion Model\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
    "\n",
    "# Disable generation (weâ€™ll use the feature extractor)\n",
    "pipeline.enable_attention_slicing()"
   ],
   "id": "8605aa55f56f5be9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1. Define Fine-Tuning Classifier",
   "id": "8fb9e12881f6ae66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from timm import create_model\n",
    "\n",
    "def create_resnet_feature_extractor() -> nn.Module:\n",
    "    extr = nn.Sequential(*list(resnet18(pretrained=True).children())[:-1])\n",
    "    return extr\n",
    "\n",
    "def create_vit_feature_extractor() -> nn.Module:\n",
    "    model = create_model('vit_base_patch16_224', pretrained=True, img_size=256)\n",
    "    return nn.Sequential(*list(model.children())[:-1])  # Use layers before classification head\n",
    "\n",
    "feature_extractor = create_vit_feature_extractor()\n",
    "\n",
    "# Update DiffusionClassifier\n",
    "class DiffusionClassifier(nn.Module):\n",
    "    def __init__(self, feature_extractor, num_classes):\n",
    "        super(DiffusionClassifier, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(768, num_classes)  # Ensure input size matches feature extractor output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use frozen feature extractor\n",
    "        with torch.no_grad():\n",
    "            features = self.feature_extractor(x).mean(dim=1)  # Global average pooling\n",
    "        out = self.fc(features)\n",
    "        return out\n",
    "\n",
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Instantiate Classifier and Print Trainable Parameters\n",
    "num_classes = len(class_names)\n",
    "classifier = DiffusionClassifier(feature_extractor, num_classes).to(device)\n",
    "print(f\"Trainable Parameters: {count_trainable_params(classifier):,}\")\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)"
   ],
   "id": "e03b31d544b982c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Train the Classifier",
   "id": "fc7bbb6727db6638"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "# Training Loop\n",
    "def train_model(classifier, dataloader, epochs=5):\n",
    "    classifier.train()  # Set model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            outputs = classifier(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "            running_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "            # Plot a random image with its real label\n",
    "            idx = random.randint(0, len(inputs) - 1)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(dataloader)}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(classifier, train_loader, epochs=20)"
   ],
   "id": "2519e457ec18b138",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4. Evaluate the Classifier",
   "id": "56a5e49838a65ebc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Function to plot a given image with its real label\n",
    "def plot_image(image, label, class_names):\n",
    "    img = image.permute(1, 2, 0).cpu().numpy()  # Convert to HWC format\n",
    "    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Unnormalize\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Label: {class_names[label]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def validate_model(classifier, dataloader):\n",
    "    classifier.eval()  # Set model to evaluation mode\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = classifier(inputs)\n",
    "            _, preds = torch.max(outputs, 1)  # Get class with highest score\n",
    "            print(preds, labels)\n",
    "            for i in range(len(preds)):\n",
    "                plot_image(inputs[i], labels[i], class_names)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "def evaluate_model(classifier, dataloader, class_names):\n",
    "    classifier.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = classifier(inputs)\n",
    "\n",
    "            # Get probabilities and predictions\n",
    "            # print(outputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            # print(probs)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            # print(probs)\n",
    "            # print(preds)\n",
    "            # print(labels)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "# Validate\n",
    "# validate_model(classifier, test_loader)\n",
    "validate_model(classifier, train_loader)\n",
    "\n",
    "# Evaluate\n",
    "# preds, labels, probs = evaluate_model(classifier, test_loader, class_names)\n",
    "preds, labels, probs = evaluate_model(classifier, train_loader, class_names)"
   ],
   "id": "b626df519a1ee4ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.1. Display Confusion Matrix and Classification Report",
   "id": "6ae39e3c20ff5892"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Confusion Matrix\n",
    "cm = confusion_matrix(labels, preds, labels=range(len(class_names)))\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print Classification Report\n",
    "print(classification_report(labels, preds, target_names=class_names))\n"
   ],
   "id": "73f7a405151323f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.2. Plot Random Samples",
   "id": "f8e0b0b2519d37b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_random_samples(dataset, preds, labels, probs, class_names, num_samples=5):\n",
    "    # Randomly select indices\n",
    "    random_indices = random.sample(range(len(dataset)), num_samples)\n",
    "\n",
    "    # Calculate number of rows needed\n",
    "    num_cols = 5\n",
    "    num_rows = (num_samples + num_cols - 1) // num_cols\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 3 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        image, true_label = dataset[idx]\n",
    "        print(idx, len(image), image.shape, true_label)\n",
    "        image = image * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        image = np.clip(image, 0, 1)\n",
    "        pred_label = preds[idx]\n",
    "        prob = probs[idx, pred_label]  # Probability of predicted class\n",
    "\n",
    "        axes[i].imshow(image.permute(1, 2, 0))  # Convert CHW to HWC for plotting\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].set_title(\n",
    "            f\"True: {class_names[true_label]}\\n\"\n",
    "            f\"Pred: {class_names[pred_label]} ({prob:.2f})\"\n",
    "        )\n",
    "\n",
    "    # Hide any remaining empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot Random Samples\n",
    "# plot_random_samples(test_dataset, preds, labels, probs, class_names)\n",
    "plot_random_samples(train_dataset, preds, labels, probs, class_names, num_samples=50)\n"
   ],
   "id": "161449e9674e7558",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
