Timestamp           | Level    | Location                             | Message
--------------------+----------+--------------------------------------+---------------------------------------------------
2025-05-18 23:38:15 | INFO     | [logger_...:setup_logger      : 153] | ‚ÑπÔ∏è Logger 'ImgClassPipe' initialized. Log file: C:\Users\Stefan\Documents\GitHub\UBB-Y3-AI-Research\model_src\experiments\mini-GCD-flat\cnn\20250518_233815_seed42\experiment_run_20250518_233815_seed42.log
2025-05-18 23:38:15 | INFO     | [executor  :__init__          : 119] | ‚ÑπÔ∏è --- Starting Experiment Run (ID: 20250518_233815_seed42) ---
2025-05-18 23:38:15 | INFO     | [executor  :__init__          : 120] | ‚ÑπÔ∏è Executor initialized for model 'cnn' on dataset 'mini-GCD-flat'
2025-05-18 23:38:15 | INFO     | [executor  :__init__          : 123] | ‚ÑπÔ∏è Local artifact storage base: C:\Users\Stefan\Documents\GitHub\UBB-Y3-AI-Research\model_src
2025-05-18 23:38:15 | INFO     | [executor  :__init__          : 127] | ‚ÑπÔ∏è Base key/prefix for this run's artifacts: experiments/mini-GCD-flat/cnn/20250518_233815_seed42
2025-05-18 23:38:15 | DEBUG    | [executor  :_validate_methods : 156] | üêû Basic method validation successful.
2025-05-18 23:38:15 | INFO     | [executor  :__init__          : 137] | ‚ÑπÔ∏è Executor configured to run methods: load_model, predict_images
2025-05-18 23:38:15 | INFO     | [executor  :run               : 166] | ‚ÑπÔ∏è Starting execution of pipeline methods...
2025-05-18 23:38:15 | INFO     | [executor  :run               : 170] | ‚ÑπÔ∏è --- Running Method 1/2: load_model (load_model_0) ---
2025-05-18 23:38:15 | DEBUG    | [executor  :run               : 195] | üêû Running with effective parameters: {'model_path_or_key': './experiments/CCSN/pvit/20250518_193300_seed42/non_nested_random_193300/pvit_best_batch_size=16_lr=3e-05_max_epochs=70_custom_head_h_cv_score0p4671.pt'}
2025-05-18 23:38:15 | INFO     | [pipeline  :load_model        :2089] | ‚ÑπÔ∏è Attempting to load model state_dict from: ./experiments/CCSN/pvit/20250518_193300_seed42/non_nested_random_193300/pvit_best_batch_size=16_lr=3e-05_max_epochs=70_custom_head_h_cv_score0p4671.pt
2025-05-18 23:38:15 | DEBUG    | [pipeline  :load_model        :2092] | üêû Initializing skorch adapter before loading state_dict...
2025-05-18 23:38:15 | DEBUG    | [pipeline  :load_model        :2106] | üêû Attempting to load model via repository: LocalFileSystemRepository
2025-05-18 23:38:15 | INFO     | [pipeline  :load_model        :2110] | ‚ÑπÔ∏è Model successfully loaded via repository from key/path: ./experiments/CCSN/pvit/20250518_193300_seed42/non_nested_random_193300/pvit_best_batch_size=16_lr=3e-05_max_epochs=70_custom_head_h_cv_score0p4671.pt
2025-05-18 23:38:15 | ERROR    | [pipeline  :load_model        :2143] | ‚ùå Failed to apply loaded state_dict to model: Error(s) in loading state_dict for SimpleCNN:
	Missing key(s) in state_dict: "features.0.weight", "features.0.bias", "features.2.weight", "features.2.bias", "features.2.running_mean", "features.2.running_var", "features.4.weight", "features.4.bias", "features.6.weight", "features.6.bias", "features.6.running_mean", "features.6.running_var", "features.8.weight", "features.8.bias", "features.10.weight", "features.10.bias", "features.10.running_mean", "features.10.running_var", "classifier.0.weight", "classifier.0.bias", "classifier.3.weight", "classifier.3.bias". 
	Unexpected key(s) in state_dict: "model.class_token", "model.conv_proj.weight", "model.conv_proj.bias", "model.encoder.pos_embedding", "model.encoder.layers.encoder_layer_0.ln_1.weight", "model.encoder.layers.encoder_layer_0.ln_1.bias", "model.encoder.layers.encoder_layer_0.self_attention.in_proj_weight", "model.encoder.layers.encoder_layer_0.self_attention.in_proj_bias", "model.encoder.layers.encoder_layer_0.self_attention.out_proj.weight", "model.encoder.layers.encoder_layer_0.self_attention.out_proj.bias", "model.encoder.layers.encoder_layer_0.ln_2.weight", "model.encoder.layers.encoder_layer_0.ln_2.bias", "model.encoder.layers.encoder_layer_0.mlp.0.weight", "model.encoder.layers.encoder_layer_0.mlp.0.bias", "model.encoder.layers.encoder_layer_0.mlp.3.weight", "model.encoder.layers.encoder_layer_0.mlp.3.bias", "model.encoder.layers.encoder_layer_1.ln_1.weight", "model.encoder.layers.encoder_layer_1.ln_1.bias", "model.encoder.layers.encoder_layer_1.self_attention.in_proj_weight", "model.encoder.layers.encoder_layer_1.self_attention.in_proj_bias", "model.encoder.layers.encoder_layer_1.self_attention.out_proj.weight", "model.encoder.layers.encoder_layer_1.self_attention.out_proj.bias", "model.encoder.layers.encoder_layer_1.ln_2.weight", "model.encoder.layers.encoder_layer_1.ln_2.bias", "model.encoder.layers.encoder_layer_1.mlp.0.weight", "model.encoder.layers.encoder_layer_1.mlp.0.bias", "model.encoder.layers.encoder_layer_1.mlp.3.weight", "model.encoder.layers.encoder_layer_1.mlp.3.bias", "model.encoder.layers.encoder_layer_2.ln_1.weight", "model.encoder.layers.encoder_layer_2.ln_1.bias", "model.encoder.layers.encoder_layer_2.self_attention.in_proj_weight", "model.encoder.layers.encoder_layer_2.self_attention.in_proj_bias", "model.encoder.layers.encoder_layer_2.self_attention.out_proj.weight", "model.encoder.layers.encoder_layer_2.self_attention.out_proj.bias", "model.encoder.layers.encoder_layer_2.ln_2.weight", "model.encoder.layers.encoder_layer_2.ln_2.bias", "model.encoder.layers.encoder_layer_2.mlp.0.weight", "model.encoder.layers.encoder_layer_2.mlp.0.bias", "model.encoder.layers.encoder_layer_2.mlp.3.weight", "model.encoder.layers.encoder_layer_2.mlp.3.bias", "model.encoder.layers.encoder_layer_3.ln_1.weight", "model.encoder.layers.encoder_layer_3.ln_1.bias", "model.encoder.layers.encoder_layer_3.self_attention.in_proj_weight", "model.encoder.layers.encoder_layer_3.self_attention.in_proj_bias", "model.encoder.layers.encoder_layer_3.self_attention.out_proj.weight", "model.encoder.layers.encoder_layer_3.self_attention.out_proj.bias", "model.encoder.layers.encoder_layer_3.ln_2.weight", "model.encoder.layers.encoder_layer_3.ln_2.bias", "model.encoder.layers.encoder_layer_3.mlp.0.weight", "model.encoder.layers.encoder_layer_3.mlp.0.bias", "model.encoder.layers.encoder_layer_3.mlp.3.weight", "model.encoder.layers.encoder_layer_3.mlp.3.bias", "model.encoder.layers.encoder_layer_4.ln_1.weight", "model.encoder.layers.encoder_layer_4.ln_1.bias", "model.encoder.layers.encoder_layer_4.self_attention.in_proj_weight", "model.encoder.layers.encoder_layer_4.self_attention.in_proj_bias", "model.encoder.layers.encoder_layer_4.self_attention.out_proj.weight", "model.encoder.layers.encoder_layer_4.self_attention.out_proj.bias", "model.encoder.layers.encoder_layer_4.ln_2.weight", "model.encoder.layers.encoder_layer_4.ln_2.bias", "model.encoder.layers.encoder_layer_4.mlp.0.weight", "model.encoder.layers.encoder_layer_4.mlp.0.bias", "model.encoder.layers.encoder_layer_4.mlp.3.weight", "model.encoder.layers.encoder_layer_4.mlp.3.bias", "model.encoder.layers.encoder_layer_5.ln_1.weight", "model.encoder.layers.encoder_layer_5.ln_1.bias", "model.encoder.layers.encoder_layer_5.self_attention.in_proj_weight", "model.encoder.layers.encoder_layer_5.self_attention.in_proj_bias", "model.encoder.layers.encoder_layer_5.self_attention.out_proj.weight", "model.encoder.layers.encoder_layer_5.self_attention.out_proj.bias", "model.encoder.layers.encoder_layer_5.ln_2.weight", "model.encoder.layers.encoder_layer_5.ln_2.bias", "model.encoder.layers.encoder_layer_5.mlp.0.weight", "model.encoder.layers.encoder_layer_5.mlp.0.bias", "model.encoder.layers.encoder_layer_5.mlp.3.weight", "model.encoder.layers.encoder_layer_5.mlp.3.bias", "model.encoder.layers.encoder_layer_6.ln_1.weight", "model.encoder.layers.encoder_layer_6.ln_1.bias", "model.encoder.layers.encoder_layer_6.self_attention.in_proj_weight", "model.encoder.layers.encoder_layer_6.self_attention.in_proj_bias", "model.encoder.layers.encoder_layer_6.self_attention.out_proj.weight", "model.encoder.layers.encoder_layer_6.self_attention.out_proj.bias", "model.encoder.layers.encoder_layer_6.ln_2.weight", "model.encoder.layers.encoder_layer_6.ln_2.bias", "model.encoder.layers.encoder_layer_6.mlp.0.weight", "model.encoder.layers.encoder_layer_6.mlp.0.bias", "model.encoder.layers.encoder_layer_6.mlp.3.weight", "model.encoder.layers.encoder_layer_6.mlp.3.bias", "model.encoder.layers.encoder_layer_7.ln_1.weight", "model.encoder.layers.encoder_layer_7.ln_1.bias", "model.encoder.layers.encoder_layer_7.self_attention.in_proj_weight", "model.encoder.layers.encoder_layer_7.self_attention.in_proj_bias", "model.encoder.layers.encoder_layer_7.self_attention.out_proj.weight", "model.encoder.layers.encoder_layer_7.self_attention.out_proj.bias", "model.encoder.layers.encoder_layer_7.ln_2.weight", "model.encoder.layers.encoder_layer_7.ln_2.bias", "model.encoder.layers.encoder_layer_7.mlp.0.weight", "model.encoder.layers.encoder_layer_7.mlp.0.bias", "model.encoder.layers.encoder_layer_7.mlp.3.weight", "model.encoder.layers.encoder_layer_7.mlp.3.bias", "model.encoder.layers.encoder_layer_8.ln_1.weight", "model.encoder.layers.encoder_layer_8.ln_1.bias", "model.encoder.layers.encoder_layer_8.self_attention.in_proj_weight", "model.encoder.layers.encoder_layer_8.self_attention.in_proj_bias", "model.encoder.layers.encoder_layer_8.self_attention.out_proj.weight", "model.encoder.layers.encoder_layer_8.self_attention.out_proj.bias", "model.encoder.layers.encoder_layer_8.ln_2.weight", "model.encoder.layers.encoder_layer_8.ln_2.bias", "model.encoder.layers.encoder_layer_8.mlp.0.weight", "model.encoder.layers.encoder_layer_8.mlp.0.bias", "model.encoder.layers.encoder_layer_8.mlp.3.weight", "model.encoder.layers.encoder_layer_8.mlp.3.bias", "model.encoder.layers.encoder_layer_9.ln_1.weight", "model.encoder.layers.encoder_layer_9.ln_1.bias", "model.encoder.layers.encoder_layer_9.self_attention.in_proj_weight", "model.encoder.layers.encoder_layer_9.self_attention.in_proj_bias", "model.encoder.layers.encoder_layer_9.self_attention.out_proj.weight", "model.encoder.layers.encoder_layer_9.self_attention.out_proj.bias", "model.encoder.layers.encoder_layer_9.ln_2.weight", "model.encoder.layers.encoder_layer_9.ln_2.bias", "model.encoder.layers.encoder_layer_9.mlp.0.weight", "model.encoder.layers.encoder_layer_9.mlp.0.bias", "model.encoder.layers.encoder_layer_9.mlp.3.weight", "model.encoder.layers.encoder_layer_9.mlp.3.bias", "model.encoder.layers.encoder_layer_10.ln_1.weight", "model.encoder.layers.encoder_layer_10.ln_1.bias", "model.encoder.layers.encoder_layer_10.self_attention.in_proj_weight", "model.encoder.layers.encoder_layer_10.self_attention.in_proj_bias", "model.encoder.layers.encoder_layer_10.self_attention.out_proj.weight", "model.encoder.layers.encoder_layer_10.self_attention.out_proj.bias", "model.encoder.layers.encoder_layer_10.ln_2.weight", "model.encoder.layers.encoder_layer_10.ln_2.bias", "model.encoder.layers.encoder_layer_10.mlp.0.weight", "model.encoder.layers.encoder_layer_10.mlp.0.bias", "model.encoder.layers.encoder_layer_10.mlp.3.weight", "model.encoder.layers.encoder_layer_10.mlp.3.bias", "model.encoder.layers.encoder_layer_11.ln_1.weight", "model.encoder.layers.encoder_layer_11.ln_1.bias", "model.encoder.layers.encoder_layer_11.self_attention.in_proj_weight", "model.encoder.layers.encoder_layer_11.self_attention.in_proj_bias", "model.encoder.layers.encoder_layer_11.self_attention.out_proj.weight", "model.encoder.layers.encoder_layer_11.self_attention.out_proj.bias", "model.encoder.layers.encoder_layer_11.ln_2.weight", "model.encoder.layers.encoder_layer_11.ln_2.bias", "model.encoder.layers.encoder_layer_11.mlp.0.weight", "model.encoder.layers.encoder_layer_11.mlp.0.bias", "model.encoder.layers.encoder_layer_11.mlp.3.weight", "model.encoder.layers.encoder_layer_11.mlp.3.bias", "model.encoder.ln.weight", "model.encoder.ln.bias", "model.heads.0.weight", "model.heads.0.bias". 
2025-05-18 23:38:15 | ERROR    | [executor  :run               : 210] | ‚ùå !!! Runtime error during 'load_model': Error applying state_dict from './experiments/CCSN/pvit/20250518_193300_seed42/non_nested_random_193300/pvit_best_batch_size=16_lr=3e-05_max_epochs=70_custom_head_h_cv_score0p4671.pt' to model.
2025-05-18 23:38:15 | INFO     | [executor  :run               : 216] | ‚ÑπÔ∏è Pipeline execution finished in 0.39s.
2025-05-18 23:38:15 | INFO     | [main      :<module>          : 251] | ‚ÑπÔ∏è --- Final Execution Results Summary ---
2025-05-18 23:38:15 | ERROR    | [main      :<module>          : 254] | ‚ùå Method load_model_0: FAILED - Error applying state_dict from './experiments/CCSN/pvit/20250518_193300_seed42/non_nested_random_193300/pvit_best_batch_size=16_lr=3e-05_max_epochs=70_custom_head_h_cv_score0p4671.pt' to model.
