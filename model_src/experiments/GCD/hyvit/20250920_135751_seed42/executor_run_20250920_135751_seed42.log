Timestamp           | Level    | Location                             | Message
--------------------+----------+--------------------------------------+---------------------------------------------------
2025-09-20 13:57:51 | INFO     | [logger_...:setup_logger      : 130] | â„¹ï¸ Logger 'ImgClassPipe' initialized. Log file: C:\Users\Stefan\Documents\GitHub\UBB-Y3-AI-Research\model_src\experiments\GCD\hyvit\20250920_135751_seed42\executor_run_20250920_135751_seed42.log
2025-09-20 13:57:51 | INFO     | [executor  :__init__          : 121] | â„¹ï¸ Local main executor log file for this run (may be temporary): C:\Users\Stefan\Documents\GitHub\UBB-Y3-AI-Research\model_src\experiments\GCD\hyvit\20250920_135751_seed42\executor_run_20250920_135751_seed42.log
2025-09-20 13:57:51 | INFO     | [executor  :__init__          : 126] | â„¹ï¸ --- Starting Executor Run (ID: 20250920_135751_seed42) ---
2025-09-20 13:57:51 | INFO     | [executor  :__init__          : 127] | â„¹ï¸ Executor initialized for model 'hyvit' on dataset 'GCD'
2025-09-20 13:57:51 | INFO     | [executor  :__init__          : 130] | â„¹ï¸ Local artifact storage base: C:\Users\Stefan\Documents\GitHub\UBB-Y3-AI-Research\model_src
2025-09-20 13:57:51 | INFO     | [executor  :__init__          : 134] | â„¹ï¸ Base key/prefix for this executor run's artifacts: experiments/GCD/hyvit/20250920_135751_seed42
2025-09-20 13:57:51 | INFO     | [pipeline  :__init__          : 165] | â„¹ï¸ Initializing Classification Pipeline:
2025-09-20 13:57:51 | INFO     | [pipeline  :__init__          : 166] | â„¹ï¸   Dataset Path: C:\Users\Stefan\Documents\GitHub\UBB-Y3-AI-Research\model_src\data\GCD
2025-09-20 13:57:51 | INFO     | [pipeline  :__init__          : 167] | â„¹ï¸   Model Type: hyvit
2025-09-20 13:57:51 | INFO     | [pipeline  :__init__          : 170] | â„¹ï¸   Artifact base key prefix for this run: experiments/GCD/hyvit/20250920_135751_seed42 (using LocalFileSystemRepository)
2025-09-20 13:57:51 | INFO     | [pipeline  :__init__          : 174] | â„¹ï¸   Default Augmentation Strategy: AugmentationStrategy.SKY_ONLY_ROTATION
2025-09-20 13:57:51 | INFO     | [pipeline  :__init__          : 175] | â„¹ï¸   Default Show First Batch Aug: True
2025-09-20 13:57:51 | INFO     | [dataset...:__init__          : 483] | â„¹ï¸ Using augmentation strategy: AugmentationStrategy.SKY_ONLY_ROTATION
2025-09-20 13:57:51 | INFO     | [dataset...:__init__          : 510] | â„¹ï¸ Detected dataset structure: fixed
2025-09-20 13:57:51 | WARNING  | [dataset...:__init__          : 512] | âš ï¸ Dataset is FIXED, but force_flat_for_fixed_cv=True. CV methods will treat train+test as a single dataset. Results might not reflect standard fixed-test evaluation.
2025-09-20 13:57:51 | INFO     | [dataset...:_load_paths_and...: 771] | â„¹ï¸ Scanning FIXED dataset from C:\Users\Stefan\Documents\GitHub\UBB-Y3-AI-Research\model_src\data\GCD\train (train) and C:\Users\Stefan\Documents\GitHub\UBB-Y3-AI-Research\model_src\data\GCD\test (test)...
2025-09-20 13:57:51 | INFO     | [dataset...:_load_paths_and...: 824] | â„¹ï¸ Final Original Dataset sizes: 10000 original train+val, 9000 original test. Offline augmented samples loaded: 0.
2025-09-20 13:57:51 | INFO     | [dataset...:__init__          : 536] | â„¹ï¸ Found 7 classes: 1_cumulus, 2_altocumulus, 3_cirrus, 4_clearsky, 5_stratocumulus, 6_cumulonimbus, 7_mixed
2025-09-20 13:57:51 | INFO     | [dataset...:_calculate_clas...: 626] | â„¹ï¸ Calculating class weights for the training set...
2025-09-20 13:57:51 | INFO     | [dataset...:_calculate_clas...: 640] | â„¹ï¸ Calculated class weights (for classes 0 to 6):
2025-09-20 13:57:51 | INFO     | [dataset...:_calculate_clas...: 642] | â„¹ï¸   - 1_cumulus (Class 0): 1.8433
2025-09-20 13:57:51 | INFO     | [dataset...:_calculate_clas...: 642] | â„¹ï¸   - 2_altocumulus (Class 1): 1.9704
2025-09-20 13:57:51 | INFO     | [dataset...:_calculate_clas...: 642] | â„¹ï¸   - 3_cirrus (Class 2): 1.2390
2025-09-20 13:57:51 | INFO     | [dataset...:_calculate_clas...: 642] | â„¹ï¸   - 4_clearsky (Class 3): 0.6645
2025-09-20 13:57:51 | INFO     | [dataset...:_calculate_clas...: 642] | â„¹ï¸   - 5_stratocumulus (Class 4): 0.7739
2025-09-20 13:57:51 | INFO     | [dataset...:_calculate_clas...: 642] | â„¹ï¸   - 6_cumulonimbus (Class 5): 0.4757
2025-09-20 13:57:51 | INFO     | [dataset...:_calculate_clas...: 642] | â„¹ï¸   - 7_mixed (Class 6): 4.1051
2025-09-20 13:57:51 | INFO     | [dataset...:__init__          : 542] | â„¹ï¸ Dataset sizes: 10000 train+val, 9000 test. Total: 19000
2025-09-20 13:57:51 | INFO     | [dataset...:__init__          : 544] | â„¹ï¸ Total combined size (for forced CV): 19000
2025-09-20 13:57:51 | INFO     | [pipeline  :__init__          : 185] | â„¹ï¸   Artifact base key prefix for this run: experiments/GCD/hyvit/20250920_135751_seed42 (using LocalFileSystemRepository)
2025-09-20 13:57:51 | INFO     | [pipeline  :__init__          : 212] | â„¹ï¸   Using Optimizer: AdamW
2025-09-20 13:57:51 | DEBUG    | [callbacks :get_default_cal...: 172] | ğŸ Default LRScheduler callback instance created with policy: ReduceLROnPlateau, kwargs: {'patience': 2, 'mode': 'min', 'factor': 0.1, 'min_lr': 1e-06, 'verbose': False}, monitor: valid_loss
2025-09-20 13:57:51 | INFO     | [pipeline  :__init__          : 269] | â„¹ï¸   Model Adapter: Initialized with HybridViT
2025-09-20 13:57:51 | DEBUG    | [executor  :_validate_methods : 189] | ğŸ Basic method validation successful.
2025-09-20 13:57:51 | INFO     | [executor  :__init__          : 168] | â„¹ï¸ Executor configured to run methods: single_train, single_eval
2025-09-20 13:57:51 | INFO     | [executor  :run               : 237] | â„¹ï¸ Starting execution of methods for Executor Run ID: 20250920_135751_seed42
2025-09-20 13:57:51 | INFO     | [executor  :run               : 246] | â„¹ï¸ --- Running Method 1/2: single_train (Op ID: single_train_0) ---
2025-09-20 13:57:51 | DEBUG    | [executor  :run               : 291] | ğŸ Running method 'single_train' with effective parameters: {'params': {'max_epochs': 60, 'lr': 5e-05, 'batch_size': 32, 'optimizer': 'AdamW', 'optimizer__weight_decay': 0.1, 'callbacks__default_lr_scheduler__policy': 'CosineAnnealingLR', 'callbacks__default_lr_scheduler__T_max': 60, 'callbacks__default_lr_scheduler__eta_min': 1e-06, 'callbacks__default_early_stopping__patience': 15, 'criterion__label_smoothing': 0.1, 'gradient_clip_value': 5.0, 'module__cnn_extractor_type': 'standard_cnn', 'module__cnn_model_name': 'efficientnet_b0', 'module__cnn_pretrained_imagenet': True, 'module__cnn_output_channels_target': 192, 'module__cnn_freeze_extractor': False, 'module__cnn_num_frozen_stages': 2, 'module__cnn_fine_tuned_weights_path': None, 'module__vit_model_variant': 'vit_b_16', 'module__vit_pretrained_imagenet': True, 'module__unfreeze_strategy': 'encoder_tail', 'module__num_transformer_blocks_to_unfreeze': 1, 'module__unfreeze_cls_token': True, 'module__unfreeze_pos_embedding': True, 'module__unfreeze_patch_embedding': False, 'module__unfreeze_encoder_layernorm': True, 'module__custom_head_hidden_dims': None, 'module__head_dropout_rate': 0.2, 'module__pipeline_img_h': 224, 'module__pipeline_img_w': 224, 'iterator_train__shuffle': True}, 'save_model': False, 'val_split_ratio': 0.1, 'results_detail_level': 2}
2025-09-20 13:57:51 | INFO     | [pipeline  :single_train      :1714] | â„¹ï¸ Starting single training run...
2025-09-20 13:57:51 | INFO     | [pipeline  :single_train      :1760] | â„¹ï¸ Using split: 9000 train / 1000 validation samples.
2025-09-20 13:57:51 | INFO     | [pipeline  :single_train      :1765] | â„¹ï¸ Applying custom parameters for this single_train run: {'max_epochs': 60, 'lr': 5e-05, 'batch_size': 32, 'optimizer': 'AdamW', 'optimizer__weight_decay': 0.1, 'callbacks__default_lr_scheduler__policy': 'CosineAnnealingLR', 'callbacks__default_lr_scheduler__T_max': 60, 'callbacks__default_lr_scheduler__eta_min': 1e-06, 'callbacks__default_early_stopping__patience': 15, 'criterion__label_smoothing': 0.1, 'gradient_clip_value': 5.0, 'module__cnn_extractor_type': 'standard_cnn', 'module__cnn_model_name': 'efficientnet_b0', 'module__cnn_pretrained_imagenet': True, 'module__cnn_output_channels_target': 192, 'module__cnn_freeze_extractor': False, 'module__cnn_num_frozen_stages': 2, 'module__cnn_fine_tuned_weights_path': None, 'module__vit_model_variant': 'vit_b_16', 'module__vit_pretrained_imagenet': True, 'module__unfreeze_strategy': 'encoder_tail', 'module__num_transformer_blocks_to_unfreeze': 1, 'module__unfreeze_cls_token': True, 'module__unfreeze_pos_embedding': True, 'module__unfreeze_patch_embedding': False, 'module__unfreeze_encoder_layernorm': True, 'module__custom_head_hidden_dims': None, 'module__head_dropout_rate': 0.2, 'module__pipeline_img_h': 224, 'module__pipeline_img_w': 224, 'iterator_train__shuffle': True}
2025-09-20 13:57:51 | DEBUG    | [param_g...:parse_fixed_hyp...: 163] | ğŸ Created LRScheduler instance: policy=CosineAnnealingLR, direct_args={}, constructor_kwargs={'T_max': 60, 'eta_min': 1e-06}
2025-09-20 13:57:51 | INFO     | [pipeline  :single_train      :1810] | â„¹ï¸ Fitting model (run_id: single_train_135751)...
2025-09-20 13:57:51 | INFO     | [standar...:__init__          :  44] | â„¹ï¸ Loaded efficientnet_b0 as feature extractor. ImageNet Pretrained: True. Natural output channels: 1280
2025-09-20 13:57:51 | INFO     | [standar...:__init__          :  55] | â„¹ï¸ Added final 1x1 projection: 1280 -> 192 channels.
2025-09-20 13:57:51 | INFO     | [standar...:_freeze_stages    :  99] | â„¹ï¸ Freezing stage 0 of efficientnet_b0 features.
2025-09-20 13:57:51 | INFO     | [standar...:_freeze_stages    :  99] | â„¹ï¸ Freezing stage 1 of efficientnet_b0 features.
2025-09-20 13:57:51 | INFO     | [hybrid_...:__init__          :  59] | â„¹ï¸ CNN Feature Extractor (efficientnet_b0) part: Trainable params: 4.25M / Total params: 4.25M
2025-09-20 13:57:51 | INFO     | [hybrid_...:__init__          :  69] | â„¹ï¸ Determined CNN feature extractor output size: 7x7 for input 224x224
2025-09-20 13:57:51 | DEBUG    | [pretrai...:__init__          :  75] | ğŸ Initializing PretrainedViT:
2025-09-20 13:57:51 | DEBUG    | [pretrai...:__init__          :  76] | ğŸ   Model Variant: vit_b_16, Pretrained: True
2025-09-20 13:57:51 | DEBUG    | [pretrai...:__init__          :  77] | ğŸ   Is Hybrid Input: True
2025-09-20 13:57:51 | DEBUG    | [pretrai...:__init__          :  79] | ğŸ   Hybrid In Channels: 192
2025-09-20 13:57:51 | DEBUG    | [pretrai...:__init__          :  80] | ğŸ   Unfreeze Strategy (Encoder Blocks): encoder_tail
2025-09-20 13:57:51 | DEBUG    | [pretrai...:__init__          :  82] | ğŸ   Num Transformer Blocks to Unfreeze: 1
2025-09-20 13:57:51 | DEBUG    | [pretrai...:__init__          :  83] | ğŸ   Unfreeze CLS: True, PosEmb: True, PatchEmb: False, EncoderLN: True
2025-09-20 13:57:51 | DEBUG    | [pretrai...:__init__          :  85] | ğŸ   Custom Head Hidden Dims: None, Head Dropout: 0.2
2025-09-20 13:57:52 | DEBUG    | [pretrai...:__init__          : 106] | ğŸ Loaded vit_b_16 from torchvision.
2025-09-20 13:57:52 | INFO     | [pretrai...:__init__          : 133] | â„¹ï¸ Adapting ViT 'vit_b_16' for hybrid input. Expected CNN feature map: 7x7.
2025-09-20 13:57:52 | INFO     | [pretrai...:__init__          : 142] | â„¹ï¸ Created hybrid input projection: 192 -> 768 channels.
2025-09-20 13:57:52 | INFO     | [pretrai...:__init__          : 159] | â„¹ï¸ Interpolating positional embedding in __init__ for hybrid ViT. Original patches: 196, Expected feature patches: 49 (7x7)
2025-09-20 13:57:52 | DEBUG    | [pretrai...:__init__          : 186] | ğŸ Unfroze custom hybrid input projection layer for ViT.
2025-09-20 13:57:52 | DEBUG    | [pretrai...:__init__          : 283] | ğŸ Created simple linear head (dropout: 0.2), in_feat=768.
2025-09-20 13:57:52 | INFO     | [pretrai...:__init__          : 293] | â„¹ï¸ PretrainedViT (hybrid) - Trainable: Hybrid Projection, CLS Token, Positional Embeddings, 1 Encoder Blocks, Encoder LayerNorm, Classification Head.
2025-09-20 13:57:52 | INFO     | [pretrai...:__init__          : 313] | â„¹ï¸ PretrainedViT (hybrid): Trainable params: 7.43M / Total params: 85.95M (8.65%)
2025-09-20 13:57:52 | INFO     | [hybrid_...:__init__          :  94] | â„¹ï¸ ViT Backend part: Trainable params: 7.43M / Total params: 85.99M
2025-09-20 13:57:52 | INFO     | [hybrid_...:__init__          : 101] | â„¹ï¸ HybridViT Total: Trainable params: 11.68M / Total params: 90.24M (12.95%)
2025-09-20 13:57:52 | DEBUG    | [adapter   :get_split_datasets: 205] | ğŸ Validation split for fold created with 1000 original samples.
2025-09-20 13:57:52 | DEBUG    | [adapter   :get_split_datasets: 245] | ğŸ No offline augmentations will be applied.
2025-09-20 13:57:52 | DEBUG    | [adapter   :get_split_datasets: 252] | ğŸ Total training split for fold created with 9000 samples.
2025-09-20 13:57:52 | DEBUG    | [adapter   :get_iterator      : 373] | ğŸ Creating DataLoader for training: dataset_len=9000, batch_size=32, shuffle=True, drop_last=False, collate_fn_type='function', loader_kwargs={'num_workers': 0, 'pin_memory': False}
2025-09-20 13:57:52 | DEBUG    | [adapter   :get_iterator      : 373] | ğŸ Creating DataLoader for validation/evaluation: dataset_len=1000, batch_size=32, shuffle=False, drop_last=False, collate_fn_type='function', loader_kwargs={'num_workers': 0, 'pin_memory': False}
2025-09-20 13:57:57 | WARNING  | [pipeline  :single_train      :1863] | âš ï¸ Error finding best epoch based on validation. Reporting last epoch (1) stats.
2025-09-20 13:57:57 | INFO     | [pipeline  :single_train      :1915] | â„¹ï¸ Main pipeline model adapter updated from single_train run: single_train_135751
2025-09-20 13:57:57 | DEBUG    | [pipeline  :_save_results     : 527] | ğŸ Results detail level overridden for this run to: 2
2025-09-20 13:57:57 | DEBUG    | [pipeline  :_save_results     : 534] | ğŸ Saving results for single_train_135751 (detail level: 2)
2025-09-20 13:57:57 | INFO     | [pipeline  :_save_results     : 632] | â„¹ï¸ Results JSON saved via repository to: experiments/GCD/hyvit/20250920_135751_seed42/single_train_135751/single_train_results.json
2025-09-20 13:57:57 | INFO     | [pipeline  :single_train      :1945] | â„¹ï¸ Plotting single_train results for single_train_135751 (plot level 2).
2025-09-20 13:57:57 | INFO     | [plotter   :plot_single_tra...: 648] | â„¹ï¸ Plotting single_train results for: single_train_135751
2025-09-20 13:57:57 | INFO     | [plotter   :plot_single_tra...: 663] | â„¹ï¸ Finished plotting for single_train: single_train_135751
2025-09-20 13:57:57 | INFO     | [executor  :run               : 298] | â„¹ï¸ --- Method single_train (Op ID: single_train_0) completed successfully in 6.11s ---
2025-09-20 13:57:57 | INFO     | [executor  :run               : 246] | â„¹ï¸ --- Running Method 2/2: single_eval (Op ID: single_eval_1) ---
2025-09-20 13:57:57 | DEBUG    | [executor  :run               : 291] | ğŸ Running method 'single_eval' with effective parameters: {'plot_level': 2}
2025-09-20 13:57:57 | INFO     | [pipeline  :single_eval       :2000] | â„¹ï¸ Starting model evaluation on the test set...
2025-09-20 13:57:57 | INFO     | [pipeline  :single_eval       :2014] | â„¹ï¸ Evaluating on 9000 test samples...
2025-09-20 13:57:57 | DEBUG    | [adapter   :get_iterator      : 373] | ğŸ Creating DataLoader for validation/evaluation: dataset_len=9000, batch_size=32, shuffle=False, drop_last=False, collate_fn_type='function', loader_kwargs={'num_workers': 0, 'pin_memory': False}
