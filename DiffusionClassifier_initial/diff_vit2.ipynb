{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Stable Diffusion-based Image Classifier Fine-Tuning with Vision Transformer as Feature Extractor",
   "id": "ee1c43d985ae7492"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 0. Setup Environment",
   "id": "cd570d31afab2125"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from sympy.strategies.core import switch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "# Get the number of GPUs\n",
    "print(torch.cuda.device_count())\n",
    "# Get the current GPU device\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name())"
   ],
   "id": "515010810120fe34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Load Modified Mini-GCD Dataset",
   "id": "5b16ae208a5c83c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import random\n",
    "\n",
    "# Check GPU availability\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# Load Dataset\n",
    "data_dir = \"modified-mini-GCD\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Class Names\n",
    "class_names = train_dataset.classes\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Show number of training samples per class\n",
    "train_class_counts = {class_names[i]: 0 for i in range(len(class_names))}\n",
    "for _, label in train_dataset:\n",
    "    train_class_counts[class_names[label]] += 1\n",
    "print(\"Train Class Counts:\", train_class_counts)"
   ],
   "id": "c773ae43af27d07a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.1. Display Sample Images",
   "id": "7d2eafa6c6e92ff2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display Sample Images\n",
    "def show_images(dataloader, class_names):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "    for idx, ax in enumerate(axes):\n",
    "        img = images[idx].permute(1, 2, 0).numpy()\n",
    "        img = (img * 0.5 + 0.5)  # Unnormalize\n",
    "        img = np.clip(img, 0, 1)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(class_names[labels[idx]])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(train_loader, class_names)"
   ],
   "id": "cd56d78cf4cabf58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Load ViT Feature Extractor (Pretrained)",
   "id": "93e83c5577d52587"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load ViT Feature Extractor (Pretrained)\n",
    "from transformers import ViTModel, ViTForImageClassification, ViTFeatureExtractor\n",
    "\n",
    "# Instantiate ViT feature extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ],
   "id": "b885c35c6ebd899f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1. Setup Diffusion-based Image Classifier with ViT Feature Extractor",
   "id": "8b4ecd908564e15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the DiffusionClassifier with ViT feature extractor\n",
    "class DiffusionClassifier(nn.Module):\n",
    "    def __init__(self, vit_model, num_classes):\n",
    "        super(DiffusionClassifier, self).__init__()\n",
    "        self.vit_model = vit_model\n",
    "        self.fc = nn.Linear(vit_model.config.hidden_size, num_classes)  # Hidden size of ViT model\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():  # Freeze ViT feature extractor\n",
    "            features = self.vit_model(x).last_hidden_state.mean(dim=1)  # Use mean of sequence (CLS token)\n",
    "        out = self.fc(features)\n",
    "        return out\n",
    "\n",
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Instantiate classifier with ViT feature extractor\n",
    "num_classes = len(class_names)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "classifier = DiffusionClassifier(vit_model, num_classes).to(device)\n",
    "print(f\"Trainable Parameters: {count_trainable_params(classifier):,}\")\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)"
   ],
   "id": "cf5a8347d258e9e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Train the model",
   "id": "ab26ba85aa3e70df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training Loop\n",
    "def train_model(classifier, dataloader, epochs=5):\n",
    "    classifier.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = classifier(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader)}\")\n",
    "\n",
    "train_model(classifier, train_loader, epochs=20)"
   ],
   "id": "6401939542b560ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4. Evaluate the Classifier",
   "id": "f46700e3145875e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate Model\n",
    "def evaluate_model(classifier, dataloader, class_names):\n",
    "    classifier.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = classifier(inputs)\n",
    "\n",
    "            # Get probabilities and predictions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "# Evaluate on Test Data\n",
    "preds, labels, probs = evaluate_model(classifier, test_loader, class_names)"
   ],
   "id": "4271125b8a61ed4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.1. Display Confusion Matrix and Classification Report",
   "id": "55bab6331e4349b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Confusion Matrix\n",
    "cm = confusion_matrix(labels, preds, labels=range(len(class_names)))\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print Classification Report\n",
    "print(classification_report(labels, preds, target_names=class_names))"
   ],
   "id": "3ccaab8bbfd85692",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.2. Plot Random Samples",
   "id": "83d3163ad8623d07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot Random Samples\n",
    "def plot_random_samples(dataset, preds, labels, probs, class_names, num_samples=5):\n",
    "    # Randomly select indices\n",
    "    random_indices = random.sample(range(len(dataset)), num_samples)\n",
    "\n",
    "    # Calculate number of rows needed\n",
    "    num_cols = 5\n",
    "    num_rows = (num_samples + num_cols - 1) // num_cols\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 3 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        image, true_label = dataset[idx]\n",
    "        image = (image * 0.5 + 0.5)  # Unnormalize\n",
    "        image = np.clip(image, 0, 1)\n",
    "        pred_label = preds[idx]\n",
    "        prob = probs[idx, pred_label]  # Probability of predicted class\n",
    "\n",
    "        axes[i].imshow(image.permute(1, 2, 0))  # Convert CHW to HWC for plotting\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].set_title(\n",
    "            f\"True: {class_names[true_label]}\\n\"\n",
    "            f\"Pred: {class_names[pred_label]} ({prob:.2f})\"\n",
    "        )\n",
    "\n",
    "    # Hide any remaining empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot random samples\n",
    "plot_random_samples(test_dataset, preds, labels, probs, class_names, num_samples=15)"
   ],
   "id": "4b78555fea17118b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
